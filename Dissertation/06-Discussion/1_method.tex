Design implications have been discussed at the end of each classroom study. This section discusses the reflection on my overall dissertation research.

\section{Design research}

Groupware research presents a lot of different challenges from research on individual tools. Groupware research involves dynamics between multiple individuals and such dynamics are heavily shaped and mediated by the tool. The tool and the team function as a single system in accomplishing a task. A single feature in the tool may change team behavior altogether. In single-user tool research, a research method that is often employed is to mock up features to test the user's reaction and mock out other features that researchers are not interested in. However, this method does not work for evaluating groupware. To understand how groupware will influence team dynamics, the groupware must be fully functional, with full capability to support team communication and coordination. The team dynamics cannot be simulated. 

Team dynamics take time to evolve. This includes the development of social awareness, situation awareness, workspace awareness, and activity awareness. Such awareness needs time to be established and maintained to a level where the team can start work effectively. This is also different from single-user research, in which user reaction to a tool can be mostly measured immediately. Longer-term research is preferred if we want to investigate the real impact of groupware. And again, to enable a longer-term investigation, full features of the groupware must be implemented. 

Teams behave totally differently with tools of different levels of collaboration support. Teams with the paper prototypes naturally do more synchronous, co-located collaboration than teams with computer prototypes supporting distributed work. To some extent, teams with the paper prototype are accomplishing a different \emph{task} than teams with computer support. 
Tasks people engage in or wish to engage in define requirements for artifacts. Those artifacts, in turn, open up new possibilities to accomplish the task, while, inevitably, introduce new errors and complexities in task performance. Again the new tasks devolve into requirements for further technology evolution, provoking another round of transaction. 

This cycle, known as task-artifact evolution (Figure~\ref{fig:task-artifact}) \citep{Carroll1992a}, drives the underlying rationale of my research on groupware: to develop a tool to drive task evolution in possible directions, understand the resulting team behavior, and in turn make design changes to the tool. The design, development, and evaluation iterations result in knowledge in team behavior and design implications for collaborative analytic tools, which eventually contribute to the exploration and understanding of the design space of groupware. 

I take a \emph{design research} approach \citep{Zimmerman2007a,Convertino2008e} to explore how interactive visualization could support collaboration. The goal of design research is to address the ``wicked problems'' \citep{Rittel1973} in real world and the increasing complexity of situations that need software support. The outcome of design research is not only artifacts of more effectiveness but also new knowledge that can inform future design. Therefore, the developed groupware is not only a team-supporting \emph{tool} that facilitates their intelligence analysis projects, but, and arguably more importantly, also a research \emph{instrument} that reveals team behaviors and patterns in that specific setting, and ultimately contribute to the knowledge pool of design rationale for groupware. 


\begin{figure}
	\centering
	\includegraphics[width=\columnwidth]{06-Discussion/img/task-artifact-1.png}
	\caption{Task-artifact co-evolution structured with design methodology from \cite{Carroll1992a} \label{fig:task-artifact}}
\end{figure}


\section{Classroom study}

A critical requirement in design research is to understand the user's needs and practices. When these needs and practices are specialized, as is the case of Intelligence Analysis, it is 
particularly important to include the target user population in 
the design process. I take Intelligence Analysis as a specialized,
domain-specific task of information analysis. Therefore it is important to understand analysts with domain knowledge, 
learn their practice, and observe their reaction to tool features \citep{Scholtz2014}. 
However, professional analysts are hard to include 
in a long-term design cycle due to confidentiality and security 
issues. The classroom study provided an opportunity with deep 
access to analysts in training. These analysts have been trained 
with knowledge and skills of intelligence analysis, and have experience with state-of-the-art analytic
tools such as Analyst's Notebook and PARC ACH. In their reflections, participants often compared CAnalytics to
those tools, as well as the different teamwork experiences. Therefore, while their feedbacks are
admittedly not identical to experienced professionals,
they do provide a deeper insight into the strengths and
weaknesses of our tool than ordinary users. In addition, the students are young learners
that are willing to employ new work practices supported by features in
tools. They are important parts of the future intelligence community. In
this sense, their practice can be treated as a view into the future of
practice of the community \citep{Martin2014}.

Studies in this research spanned multiple user sessions.
This gave participants time to learn to adapt to team functions and to appropriate
the tool to best serve their team purpose. Teams were able to explore different team strategies and to
make changes if they got stuck \citep{Stahl2006}. For example, we
noticed that two teams decided to change the use of the tool halfway in
their analysis. One team started with dividing work by case documents
but later decided members should annotate different entity types.
Another team started with an accretion strategy by annotating all
entities and later discovered that this strategy brought too much
noise and decided to clean out irrelevant entities (filtering
strategy). Such change occurs as a consequence of increased awareness of
team functions and tool capabilities, which takes time to develop.

With deep access to these analysts, I can interpret and triangulate our data from multiple sources. I qualitatively analyzed participants' feedback to understand their first-person experience and corroborated them with surveys and interaction logs. The interaction logs provided us a detailed view of their analysis process and allowed us to quantitatively characterize their team behavior. Finally, their analytic products, including the visual artifacts and team reports, helped us distinguish team outcomes. In summary, this research contributes to the study of computer-supported collaboration work with valuable empirical data.

Yet classroom study also has limits. For example, many factors and
variables could exist that affect team performance. The fact that these
factors are often impossible to model or control adds to the difficulty
in data analysis (e.g.~teammate absence). Also, data collection is
challenging because team interactions are not always accessible. Teams
can choose to work synchronously or asynchronously, and it is difficult
to predict when or where the interaction of most interest is to occur.
Verbal communication is not accessible, which could be useful to infer
team awareness as a complement to interaction logs. Our work identifies
both positive evidence and problematic situations, and propose potential
solutions and possible hypotheses, yet rigorously evaluating these
solutions and validating hypotheses is beyond this study. Lab studies
and case studies can be conducted in the future to address these
problems with greater control and deeper data access.
