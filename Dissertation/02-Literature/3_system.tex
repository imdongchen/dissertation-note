\section{Technology to Support Collaborative Information Analysis}

A number of tools have been developed to support information analysis. For example, the Analyst’s Notebook \citep{IBM} and ACH \citep{PARC} are widely used in intelligence analysis areas. However, these tools were developed for individual use only. Prior work demonstrated that the work of information analysis at non-trivial scales is fundamentally collaborative. In practice analysts have to manually share notebooks or graphs to coordinate their work.

As the need of support for collaborative information analysis is capturing increasing attention, more technologies are being developed. Most of the tools take advantage of visualization techniques and display awareness information in a visual way. This is not hard to understand since the human visual channel has a high bandwidth and can take in a large amount of information in a short time. Visualization can efficiently capture user attention and represent awareness information in a concise and vivid way. Fussell and her colleagues \citep{Balakrishnan2010e,Goyal2013,Goyal2016} have done a series of controlled, comparative laboratory experiments investigating the effect of visualization on collaboration. They found that groups using visualization tools had better performance and shared visualization increased group discussion. Various visualization techniques have been designed to facilitate different facets of awareness, and most of them fall into the categories below. 

- Who are collaborators. Knowledge of the existence of potential collaborators and their skills and expertise is important. \cite{Forsen2009a} proposed the concept of Pinpoint, an interactive visualization radially presenting colleagues that are most closely related and affords browsing, filtering, and further exploration of the networks of the organization. \cite{Marlow2015a} examined the effect of visualization on the attitude towards peer collaborators. They found that different details of visualization of work history have a different impact on behaviors and attitudes towards collaborators, which further influence group engagement.
  
- What are they doing. While it is easy to know what collaborators are doing in face-to-face settings, e.g. pointing at a figure, walking towards a whiteboard, etc., such signals are nonexistent in distributed collaboration and have to be explicitly supported by technology. Therefore \cite{stefik1987wysiwis} introduced WYSIWIS (What You See Is What I See), in which collaborators share the same view. While this design ensures everyone looks at the same thing, it blocks production as only one person has control of the view at one turn. A relaxed-WYSIWIS design \citep{Gutwin1998h} was then proposed, which enables team members to have control of their own view while having a miniature overview of partner’s workspace, known as radar view \citep{Gutwin1996}. Radar view conveys information not only about what collaborators are doing, but also where they are working on. Greenberg et al. (1996) also proposed the idea of telepointer, where participants can see the mouse cursor of their colleagues. They then further augmented telepointers with traces be means of visualization of the previous motion of the remote cursor. This provides a bit of context of the cursor and makes the mouse gestures easier to interpret. Similarly, \cite{Hajizadeh2013} attempted to support awareness of collaborator’s activities by visualizing their bushing actions. They found that persistent selection, which adds a “fading-away” effect to past selections, gets people more aware of collaborators’ activities. Technologies as such are often applied in synchronous collaboration, attempting to help collaborators stay aware of what others are doing by embodying a remote gesture in visualization.

- What have they done. People may not be active in a team for all the time. When they come back it is important to know what collaborators have done and what changes they have made. In their approach to visualizing the change of data, \cite{Schumann2013a} used color to encode when a node was created. They also provided a replay function to show the evolution. Similarly, \cite{Edwards1997i} visualized the history as a non-linear tree and argued that the design enabled transition from loosely-coupled work to tightly-coupled collaboration. In the context of collaborative Web search, \cite{Paul2010} posited that displaying users’ search history avoids duplicated efforts and increases team performance. 

- Information sharing. Making sure everyone in the group has access to all information and is aware of the existence of the information is essential for collaborative information analysis. Participants can implicitly share information. For example, \cite{Goyal2014} examined the consequence when user-generated notes are automatically shared with other teammates. They found that participants remembered more clues about the task and participants perceived the tool more useful when implicit sharing is available. However, users may not want to share everything. They also need more control over what to share and what to keep private \citep{Mahyar2013b}. \cite{Convertino2011} designed an explicit but low-cost sharing mechanism through a “Copy-To” button. Analysts could create geo features on their private map and only share those features they wanted to onto a public map by manually clicking on the button. The function grants users explicit control over their acts but requires extra efforts. \cite{Nobarany2012} attempted to combine the advantages of explicit and implicit sharing. They introduced the concept of “obscurity of privacy” and posited that information in a public space can still maintain some level of privacy, depending on the availability of the information to others, awareness of the availability, and the amount of attention it receives. In their system, users can mark a piece of information as private, public, or published. Private information is only kept to the user who produced it. Public information is visible to all group members but does not show up on a highlighted position. Published pieces are not only visible to the group but also highlighted. The effect of this more sophisticated sharing mechanism, however, required further research, according to the authors. 

- Insight sharing. Sharing insights enables people to build on the endeavors of teammates and get aware of what others are thinking or why they are doing that. In the project of Many Eyes \citep{Viegas2007}, a social visual analytic platform where people can collectively analyze data and share visualizations, the primary way to exchange ideas is through the comment system, where users can see other people’s comment on a specific state of visualization. Another social platform, sense.us \citep{Heer2008a}, supports doubly-linked discussion, which means that comments and visualizations are bi-linked: a comment is attached with a visualization (same as Many Eyes), and a specific visualization is linked to comments if anyone has already commented on that state. 

Annotation is a widely used technology to externalize analysts’ insights. For example, \cite{Xiao2008c} asked participants to annotate the rationale when they are performing an act, and found these annotations help other people understand why their colleagues did that. \cite{Hopfer2007b} designed a geospatial annotation mechanism, which attached annotation to a specific area of the visualization. This provides the annotation with clearer context. \cite{Dorn2015a} went further and constrained an annotation with a temporal dimension. Their system allowed students to annotate on a specific position of a video at a specific time point. The system helped instructors know better about students’ puzzles and problems. 

However, tools supporting information analysis are often targeted at a single phase of activity, and thus not supporting the whole workflow. For example, research efforts have been made to understand information collection and modeling \citep{Shah2014i, Jansen2010c}, but little support is provided to extend these models to analysis. Techniques such as Information Extraction and Weight (IEW) helps structures data evidence but offers no structure to turn the evidence to hypothesis development. Similarly, tools supporting the activity of data analysis assume data has been modeled. For example,  Analysis of Competing Hypotheses (ACH) assumes that data has
been modeled, and that relevant evidence can be adduced appropriately to various
hypotheses, but provides no structured support for either. Analytic tools such as interactive visualization emphasize presenting data in insightful means but provides no utility to data re-modeling.
\cite{Ware2012} warned of the \emph{``asymmetry in data rates''} (p.382),
pointing out that visual analytic tools emphasized data flowing from systems to
users far more than from users to systems. Functionalities are mostly designed
to adjust data representation rather than modeling, which are in fact equally
important. Similar calls were made in other data intensive task domains as well. For
example, in interactive machine learning, researchers \citep{Chen2016,Amershi2015} call for an all-in-one environment in which machine learning
practitioners can iteratively refine training data and evaluate model performance through
visualization in one place. Our work aligns with these efforts, and contribute to the design and
evaluation of an integrated workspace in supporting information analysis tasks.

Another gap in the research of collaborative analytic technology is the lack of rigorous empirical evaluations. Little is known how analysts in the real world will employ these technologies in their work processes, and how their work processes will be transformed by these technologies. This study tries to investigate effects of technologies on different facets of activity awareness, and to examine the group processes that make the effects happen.