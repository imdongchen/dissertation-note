% discussion v2
\section{Discussion}

\subsection{Difference from prior work}

Our overarching research objective is to investigate software designs that better support the need of collaborative information analysis. The fluid settings of many team activities (synchronous/asynchronous, collocated/distributed), the complexity of their tasks, the need to analyze high-volume and complicated-structured data, make the task challenging. Current analytic teams have little support; most tools (e.g. PARC ACH and IBM Analyst's Notebook) are designed for single user and only part of the analysis process. By providing effective technology to aspects of information analysis (e.g. evidence collection, evidence schematization, hypothesis generation, and overall coordination), we can make analytic teams have more efficient workflow, better team performance, and more engaging work.

In a comprehensive review of CSCW papers by \cite{Wainer2007}, they found that empirical papers can be evaluative, which describe an innovative groupware followed by a small part of evaluation, or descriptive, which describe team behavior in a work environment with or without an existing tool, but none combines development of an innovative groupware with detailed observation of team behavior applying the tool. This is possibly due to the great challenge in groupware assessment. As Stahl \cite{Stahl2006} put it, \textit{``To see how it really supports groups, groups must use it under relatively naturalistic conditions and for a long enough time to become comfortable with it. But this requires building a sufficiently complete and robust prototype for group usage, finding an appropriate group of users, training users in its use, and involving them in a meaningful application of the software that properly exercises the functionality of interest.''} (P. 197). Our study aims to fill in that void: a design research that implements an tool, observe how teams use it in a complex task, probe design implications, and iteratively improve the tool.

The goal is two-folds: 1. to design and evaluate the tool for supporting collaborative information analysis; 2. to use the tool as a means to probe how teams collaborate with technology mediation in complex tasks. The two goals serve each other: the result of the observation informs the design the of tool, and new implementation probes various aspects of team collaboration behavior for new insights.

Our study is close to real world scenarios in three aspects. First, our participants are students who are being trained to become professional analysts. User-centered design is essential to understand the challenges of information analysts \cite{Scholtz2014}. However, professional analysts are often limited to access due to security and confidential issues. Attempt to involve them in long-term design process as in our study is almost impossible. Instead, many researches recruit college students in their empirical study. However, these participants lack the advanced knowledge and skills (e.g. ACH, link analysis) that are often used. Our participants are mostly trained for three years in the program. Before the study, the students have taken nine weeks of the course, and have used PARC ACH, IBM Notebook, Evidence Matrix, and other analytic techniques to solve similar projects. They are familiar with the practice of the community.

Second, the task content is close to real world cases. The task is complex, containing seven cases, and involves various information sources (news media, social media, witness report, sensor data, etc.). Information can be of various reliability and credibility, requiring the analysts to investigate and judge. The task result is open-ended, similar to the real case which usually has no single answer. Analysts have to make their best hypotheses based on their provided information.

Third, the study context is similar to real world environment. Students have multiple courses and projects, similar to analysts who often are occupied in multiple work threads. Our participants have fluid collaborative settings (synchronous/asynchronous, collocated/distributed). This is similar to professional analysts, who often find themselves in different collaboration situations, depending on the physical constraint and their task needs.


\subsection{Implications for theory and design}

\paragraph{Data collection as part of analysis}
A common misconception of information analysis is analysis of a specific set of data. Existing analytic techniques and tools such as ACH often assume that data has been modeled and can be applied directly to hypothesis development, but provide no support for data modeling at all. Analysts are treated as ``consumers'' of data.

However, we find that in our study participants spent a significant amount of time in determining collaboratively what to collect, what criteria to use, and what schema to model the annotations. These issues depend on what questions the team is to answer and how to answer the question. The team must collaboratively frame the question and decide the data gap to answer the question. Teams that failed to do ended up with inconsistent data models, which added difficulty to next-step analysis.

Also, our log analysis reveals that data collection and data analysis are closely coupled along the process. Analysts do not work linearly from data collection to analysis, but work on both simultaneously and iteratively. As team's framing of their question evolves along time, their revise their evidence to support the frame. While prior works have observed the integrated process of data collection and analysis by qualitatively coding participant's behavior, our log analysis complements the finding by capturing and visualizing analysts' real interactions.

% waterfall
interestingly, the misconception is analogous to the waterfall model in the software development domain. The waterfall model features a sequential process that flows downwards through the phases of requirement conception, software design, software implementation, testing and maintenance. Many critics have pointed out that clients may not know exactly what their requirements are before they see the working software and designers may not be fully aware of future difficulties in a new software product. Therefore an iterative design process is often required that leads to reframe user requirements, redesign, redevelopment, and retesting. Similarly, in an information analysis cycle, analysts often need to change their analytic problem, and re-collect data that fills the gap between the problem and what they already know, and redo the analysis. An iterative analysis process is required and can be facilitated by close coupling of the data collection and analysis process.

% Views as team resources
\paragraph{Views as resources}

\hl{views should be sharable, reusable, extensible, collapsible, and comparable}

In addition to sharing of data, we find that views of data should become shareable resources as well. With the identical data pool, analysts often have different views of data. For example, analysts can apply a filter to have a reduced data view, highlight an area to sharpen analytic focus, and re-layout the node-link graph to cluster relevant entities. While the data pool represents the information the team have available, individual views of the data reflect analyst's \emph{interpretation} toward the information. Therefore we propose that just like data, views, which embodies interpretation of data, should be shareable.

Views as resources should also be extensible, and reusable. For example, several participants reflected that there were situations when they found a collaborator's view useful and wanted to build their own work upon that view without manually reproducing the view. With views as resources, individuals can take the views to their need. They can also deliberatively share their own view when they feel other collaborators will be interested. Shared views are interactive rather than static images, so that analysts can still perform full functions including filtering and highlighting, and are able to evolve the view with collective team efforts, a critical requirement emphasized in \cite{Carroll2013}


We found that views should be treated as shareable resources. Complex cognitive and collaborative activities are often achieved through meaningful views of data, as externalization of human thought, offload of cognitive demand, and mediation of team cognition. In our current system, teams share the same data pool but have individual views of data. This was originally designed on purpose to enable individuals to have their own arrangement of data and to avoid interference. But we found flaw in such design as different views could hinder teams from collaboratively developing a theory. We propose that views should be another \emph{resource} in addition to others like data and tools, which could be shared, reused, and evolved. Teammates could deliberatively share their own view when they believe In our planned next version of tools, individuals still have personal views but can always share views as public resources. Teammates can take shared views for their own use and continue developing the views without duplicating it. This is different from public/private workspace as implemented in \cite{Convertino2011}, in which teams only have a single public space. With complex tasks multiple threads may be undertaken at the same time and sharing in one space may cause confusion. This is also different from what \cite{Nobarany2012} implemented as a means to facilitate reuse of views because their views are static images and limit the possibility to evolve with collective team efforts.


% collapse information
Several teams reflected that the node-link graph becomes difficult to read after the size of entities becomes large. Nodes and links are clustered in the view and get significant overlap. While applying a filter can always reduce the data, there are situations when analyst need to get an overview of the complete story without data filtered out. One way is to enable collapse of information. Connected nodes are often representing a same topic. An event node linked with a location, an organization, and several people nodes makes up a complete event. When details are not desired, these nodes can collapse into a single event node, or \emph{an evidence cluster}. The cluster can continued to be collapsed until there only exist several disconnected evidence clusters. The capability of collapsing and expanding information is important as it saves screen space and helps participants sharpen their analytic focus.



% view of uncertainty

\paragraph{Conflict and uncertainty  as collaboration opportunity }

% Role of technology
\paragraph{Role of technology}
We reflect on the role of technology in mediating collaboration.

Adoption of any technology will eventually change the workflow in teams. Teamwork is inevitably reorganized by the constraints of technology.

For example, by enabling the sharing of the same data models, CAnalytics ``forces'' teams to work in a closer-coupled way. With traditional tools, teammates have separate tools and model separate data structures for each tool. The way one individual formats data does not directly affect his teammate's schematization. In CAnalytics, however, if team members employ different rules of collecting evidence, the team will end up with inconsistent data models, which eventually impedes analysis. To accommodate to such tool constraint, the team must work more closely, ensuring an agreement of strategy of evidence collection.

Both the users and designers of collaborative tools must be cautious not to be too ambitious of tools. Tool users must realize that the tool only ``mediates'' team collaboration, but does not ensure smooth collaboration. For example, two teams in our study reflected that their team conversation decreased dramatically compared to previous project because they felt they knew teammates' activities through the tool and ``there seems no need to talk'' (P??), but the lack of communication eventually harmed their collaboration. Designers, on the other hand, should be aware that technology is not support every aspect of collaborative information analysis. From our study, we find three aspects that technology could play a significant role apart from data sharing:

1. provide feedback. Team work consists of two major phases: establishing a plan and executing a plan. When the teams are establishing a plan, they discuss team's overall goal, strategies and tactics to reach the goal, resources available, and role responsibilities. This process usually requires high frequency of conversation turns, and is more effective in face-to-face communication. Participants in our study spent a significant amount of time in class on discussing the plan. During the execution of the plan, individuals perform their responsible parts of the plan. A critical part is to provide evidence from which individual's level of understanding of the plan can be inferred. Such evidence is usually given off as a side effect of action without extra verbal effort in face-to-face settings: a correct action indicates understanding whereas a wrong action or failure to act indicates misunderstanding. In remote settings, however, deliberative signaling needs to be designed. Technology can help in relaying such information when the user interacts with the system. For example, the tool coordinator in our tool provides visual feedback on where teammates are working and the notification system streams live changes teammates made. These updates help teammates monitor whether collaborators have understood the team plan. The feedback is effective because users do not need to explicitly state their understanding of the plan.


2. makes teamwork engaging. A positive emerging finding is that the collaborative tool seemed to increase Participant's engagement. Students stated that seeing teammates' real-time activities and their own activities being exposed to teammates motivated them to contribute, made them peace at mind, and increased their accountability. This finding is worth attention as group work is often blamed for \emph{social loafing} \cite{Karau1993},  referring to the problem that individuals tend to work less hard when in a group than when they are working as individuals. Our finding provides evidence that appropriate awareness design is likely to reduce that effect, and may even make teamwork engaging. The finding could have direct impact on education---not only the education of information analysis as in our study, but also education of other domains as well: technology that enables collaborative learning could increase students' engagement (e.g. \cite{zheng2015}).


3. turn conflict into cooperative activities. While our participants believe they are more willing to communicate directly over conflicts, technology can assist in detecting such conflicts and turn them into opportunities for cooperative activities.

\paragraph{Managing affordances in opportunist coupling}

\paragraph{Narrowing down data}

\paragraph{Deletion as contribution}

% Deletion from artifact is socially difficult, compare to wiki but should relate to CIA task.
% Make deletion socially acceptable
We found that compared to ``adding'' data to the tool, participants had more difficulty in ``deleting'' things, especially when they were created by other people. Such difficulty was not technically, but socially. For example, we found from the system log that when an individual updates a relationship between two entities that is either incomplete or conflicting, s/he usually creates a new relationship with the updated information without modification or deletion of the old one. We imagine that the reason behind is that deleting other's work is showing disagreement to teammates, which could cause discomfort to both sides \cite{Asch1951}. The problem occurs in other domains as well, for example, in Wiki collaboration \cite{grudin2010}, where people feel uncomfortable deleting other member's writing. Usually a version control system is employed so that prior contribution is always available even after deleted. However,the issue was more complex in the context of information analysis as the task itself and data types involved in the task are more complex than text. A possible way to reduce the effect is to weaken the indicator of disagreement. For example, instead of permanently deletion, users can ``archive'' an object for later use, or temporarily hide objects. 

% We also observed that compared to ``adding'' things to shared artifact, participants had more difficulty ``deleting'' things. Such difficulty was not technically, but socially. For example, we found in the system log that instead of deleting an old link created by a teammate, the user created another link with updated information. We imagine that by deleting other's work, people feel they are denying teammate's contribution. Such disagreement can easily make both sides uncomfortable \cite{Asch1951}. Keeping out-of-date information, however, unnecessarily complicated the shared artifact, and confused them eventually with mixed information.
